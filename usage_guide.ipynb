{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Profiling Guide\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Import time profilers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from python_profiling.time_profiling.time_profiler import (\n",
    "    TimeProfiler, \n",
    "    ThreadBasedTimeProfiler\n",
    "    )\n",
    "from python_profiling.time_profiling.timeit_profiler import TimeItProfiler\n",
    "from python_profiling.time_profiling.line_time_profiler import LineTimeProfiler\n",
    "from python_profiling.time_profiling.call_graph_time_profiler import CallGraphTimeProfiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_function(dummy_arg):\n",
    "    res = 0\n",
    "    for _ in range(100000):\n",
    "        res +=  1\n",
    "    return  dummy_arg\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initialize time profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeProfiler(profiling_timer=<built-in function time>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_profiler = TimeProfiler(profiling_timer=time.time)\n",
    "time_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Profiling with time profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeProfilerResult(profiler=TimeProfiler, profiled_func=dummy_function)\n",
      "Profiler: TimeProfiler(profiling_timer=<built-in function time>)\n",
      "Profiled Function: dummy_function\n",
      "Function Args: None\n",
      "Function Kwargs: {'dummy_arg': 1}\n",
      "Function Result: 1\n",
      "Function Executions Time: 0.004989 seconds\n",
      "Function Exception: None\n"
     ]
    }
   ],
   "source": [
    "time_profiler_profiling_result = time_profiler.profile(func=dummy_function, **{'dummy_arg': 1})\n",
    "print(repr(time_profiler_profiling_result))\n",
    "print(time_profiler_profiling_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initialize timeit profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeItProfiler(timer=<built-in function time>, number=100, repeat=2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit_profiler = TimeItProfiler(timer=time.time, number=100, repeat=2)\n",
    "timeit_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Profiler with timeit profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeItProfilerResult(profiler=TimeItProfiler, profiled_func=<function dummy_function at 0x7ff6908511b0>)\n",
      "Profiler: timer=<built-in function time> number=100 repeat=2\n",
      "Profiled Function: dummy_function\n",
      "Function Kwargs: {'dummy_arg': 1}\n",
      "Function Result: 1\n",
      "Function Min Executions Time: 0.502324 seconds\n",
      "Function Avg of 2 Executions Time: 0.506027 seconds\n",
      "Function Max Executions Time: 0.509730 seconds\n",
      "Function Exception: None\n"
     ]
    }
   ],
   "source": [
    "timeit_profiler_profiling_result = timeit_profiler.profile(func=dummy_function, **{'dummy_arg': 1})\n",
    "print(repr(timeit_profiler_profiling_result))\n",
    "print(timeit_profiler_profiling_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initialize line time profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LineTimeProfiler()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_time_profiler = LineTimeProfiler()\n",
    "line_time_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Profiling with line time profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LineTimeProfilerResult(profiler=type, profiled_func=<function dummy_function at 0x7ff6908511b0>)\n",
      "Profiler: <class 'python_profiling.time_profiling.line_time_profiler.LineTimeProfiler'>\n",
      "Profiled Function: dummy_function\n",
      "Function Kwargs: {'dummy_arg': 1}\n",
      "Function Result: 1\n",
      "Function Profiling Result: Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 0.072833 s\n",
      "File: /var/folders/k9/6y59tr5d45s1nynfg_sv5zr80000gn/T/ipykernel_24763/2019259526.py\n",
      "Function: dummy_function at line 1\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     1                                           def dummy_function(dummy_arg):\n",
      "     2         1       1000.0   1000.0      0.0      res = 0\n",
      "     3    100001   36779000.0    367.8     50.5      for _ in range(100000):\n",
      "     4    100000   36053000.0    360.5     49.5          res +=  1\n",
      "     5         1          0.0      0.0      0.0      return  dummy_arg\n",
      "\n",
      "\n",
      "Function Exceptions: None\n"
     ]
    }
   ],
   "source": [
    "line_time_profiler_profiling_result = line_time_profiler.profile(func=dummy_function, **{'dummy_arg': 1})\n",
    "print(repr(line_time_profiler_profiling_result))\n",
    "print(line_time_profiler_profiling_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initialize call graph time profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CallGraphTimeProfiler(sort_key='time', func_filter=None, top_n=5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_graph_time_profiler = CallGraphTimeProfiler(sort_key='time', func_filter=None, top_n=5)\n",
    "call_graph_time_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Profiling with call graph time profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CallGrapthTimeProfilerResult(profiler=CallGraphTimeProfiler, profiled_func=<function dummy_function at 0x7ff6908511b0>)\n",
      "Profiler: sort_key='time' func_filter=None top_n=5\n",
      "Profiled Function: dummy_function\n",
      "Function Kwargs: {'dummy_arg': 1}\n",
      "Function Result: 1\n",
      "Function Profiling Result: Fri Apr 25 15:45:44 2025    result.prof\n",
      "\n",
      "         3 function calls in 0.006 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.006    0.006    0.006    0.006 2019259526.py:1(dummy_function)\n",
      "        1    0.000    0.000    0.000    0.000 context_managers.py:120(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n",
      "\n",
      "Function Exceptions: None\n"
     ]
    }
   ],
   "source": [
    "call_graph_time_profiler_profiling_result = call_graph_time_profiler.profile(func=dummy_function, **{'dummy_arg': 1})\n",
    "print(repr(call_graph_time_profiler_profiling_result))\n",
    "print(call_graph_time_profiler_profiling_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features of ever profiling result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* get profiling result in form of dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'profiler': TimeProfiler(profiling_timer=<built-in function time>),\n",
       " 'profiled_func': <function __main__.dummy_function(dummy_arg)>,\n",
       " 'func_args': None,\n",
       " 'func_kwargs': {'dummy_arg': 1},\n",
       " 'func_result': 1,\n",
       " 'func_execution_time': 0.004988908767700195,\n",
       " 'func_exception': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_profiler_profiling_result.profiling_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* add meta data to profiling result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-25 15:45:44,959 | python_pytorch_profiling_logger | INFO] -> profiling data has been extended with context {'additional information': 'additional information'} successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'profiler': TimeProfiler(profiling_timer=<built-in function time>),\n",
       " 'profiled_func': <function __main__.dummy_function(dummy_arg)>,\n",
       " 'func_args': None,\n",
       " 'func_kwargs': {'dummy_arg': 1},\n",
       " 'func_result': 1,\n",
       " 'func_execution_time': 0.004988908767700195,\n",
       " 'func_exception': None,\n",
       " 'additional information': 'additional information'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_profiler_profiling_result.add_context(context={'additional information': 'additional information'})\n",
    "time_profiler_profiling_result.profiling_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* remove meta data from profiling result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-25 15:45:44,977 | python_pytorch_profiling_logger | INFO] -> context additional information has been removed from profiling data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'profiler': TimeProfiler(profiling_timer=<built-in function time>),\n",
       " 'profiled_func': <function __main__.dummy_function(dummy_arg)>,\n",
       " 'func_args': None,\n",
       " 'func_kwargs': {'dummy_arg': 1},\n",
       " 'func_result': 1,\n",
       " 'func_execution_time': 0.004988908767700195,\n",
       " 'func_exception': None}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_profiler_profiling_result.remove_context('additional information')\n",
    "time_profiler_profiling_result.profiling_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* get function execution result, function keyword arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function result: 1\n",
      "Function keyword arguments: {'dummy_arg': 1}\n"
     ]
    }
   ],
   "source": [
    "print(f'Function result: {time_profiler_profiling_result.func_result}')\n",
    "print(f'Function keyword arguments: {time_profiler_profiling_result.func_kwargs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Serialize profiling result to JSON, TXT,  YAML files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from python_profiling.python_profiling_enums import SerializerStrategy\n",
    "\n",
    "# time_profiler_profiling_result.dump(\n",
    "#     file_path = 'time_profiling_result.json',\n",
    "#     mode='w',\n",
    "#     serializer_strategy=SerializerStrategy.JSON\n",
    "#     )\n",
    "\n",
    "# time_profiler_profiling_result.dump(\n",
    "#     file_path = 'time_profiling_result.txt',\n",
    "#     mode='w',\n",
    "#     serializer_strategy=SerializerStrategy.TXT\n",
    "#     )\n",
    "\n",
    "# time_profiler_profiling_result.dump(\n",
    "#     file_path = 'time_profiling_result.yaml',\n",
    "#     mode='w',\n",
    "#     serializer_strategy=SerializerStrategy.YAML\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time profiling with time profiling decorators\n",
    "p.s ever profiling result is exacly the  same as  been shown  before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_profiling.time_profiling.time_profiling_decorators import (\n",
    "    TimeProfilerDecorator, \n",
    "    TimeItProfilerDecorator,\n",
    "    LineTimeProfilerDecorator,\n",
    "    CallGraphTimeProfilerDecorator\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Profiling with time profiling decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_profiling.python_profiling_enums import TimeProfilerStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeProfilerResult(profiler=ABCMeta, profiled_func=dummy_function)\n",
      "Profiler: <class 'python_profiling.time_profiling.time_profiler.ThreadBasedTimeProfiler'>\n",
      "Profiled Function: dummy_function\n",
      "Function Args: None\n",
      "Function Kwargs: {'dummy_arg': 1}\n",
      "Function Result: None\n",
      "Function Executions Time: 0.005847 seconds\n",
      "Function Exception: None\n"
     ]
    }
   ],
   "source": [
    "@TimeProfilerDecorator(time_profiler_strategy=TimeProfilerStrategy.THREAD_BASED)\n",
    "def dummy_function(dummy_arg):\n",
    "    res = 0\n",
    "    for _ in range(100000):\n",
    "        res +=  1\n",
    "    return  dummy_arg\n",
    "\n",
    "\n",
    "time_profiler_decorator_profiling_result = dummy_function(dummy_arg=1)\n",
    "print(repr(time_profiler_decorator_profiling_result))\n",
    "print(time_profiler_decorator_profiling_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Profiling with timeit profiling decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeItProfilerResult(profiler=TimeItProfiler, profiled_func=<function dummy_function at 0x7ff690831480>)\n",
      "Profiler: timer=<built-in function time> number=100 repeat=2\n",
      "Profiled Function: dummy_function\n",
      "Function Kwargs: {'dummy_arg': 1}\n",
      "Function Result: 1\n",
      "Function Min Executions Time: 0.495807 seconds\n",
      "Function Avg of 2 Executions Time: 0.498384 seconds\n",
      "Function Max Executions Time: 0.500962 seconds\n",
      "Function Exception: None\n"
     ]
    }
   ],
   "source": [
    "@TimeItProfilerDecorator(timer=time.time, number=100, repeat=2)\n",
    "def dummy_function(dummy_arg):\n",
    "    res = 0\n",
    "    for _ in range(100000):\n",
    "        res +=  1\n",
    "    return  dummy_arg\n",
    "\n",
    "timeit_profiler_decorator_profiling_result = dummy_function(dummy_arg=1)\n",
    "print(repr(timeit_profiler_decorator_profiling_result))\n",
    "print(timeit_profiler_decorator_profiling_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Profiling with line time profiling decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LineTimeProfilerResult(profiler=type, profiled_func=<function dummy_function at 0x7ff690831360>)\n",
      "Profiler: <class 'python_profiling.time_profiling.line_time_profiler.LineTimeProfiler'>\n",
      "Profiled Function: dummy_function\n",
      "Function Kwargs: {'dummy_arg': 1}\n",
      "Function Result: 1\n",
      "Function Profiling Result: Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 0.069856 s\n",
      "File: /var/folders/k9/6y59tr5d45s1nynfg_sv5zr80000gn/T/ipykernel_24763/2737703488.py\n",
      "Function: dummy_function at line 1\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     1                                           @LineTimeProfilerDecorator()\n",
      "     2                                           def dummy_function(dummy_arg):\n",
      "     3         1       1000.0   1000.0      0.0      res = 0\n",
      "     4    100001   34976000.0    349.8     50.1      for _ in range(100000):\n",
      "     5    100000   34878000.0    348.8     49.9          res +=  1\n",
      "     6         1       1000.0   1000.0      0.0      return  dummy_arg\n",
      "\n",
      "\n",
      "Function Exceptions: None\n"
     ]
    }
   ],
   "source": [
    "@LineTimeProfilerDecorator()\n",
    "def dummy_function(dummy_arg):\n",
    "    res = 0\n",
    "    for _ in range(100000):\n",
    "        res +=  1\n",
    "    return  dummy_arg\n",
    "\n",
    "line_time_profiler_decorator_profiling_result = dummy_function(dummy_arg=1)\n",
    "print(repr(line_time_profiler_decorator_profiling_result))\n",
    "print(line_time_profiler_decorator_profiling_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Profiling with call graph time profiling decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CallGrapthTimeProfilerResult(profiler=CallGraphTimeProfiler, profiled_func=<function dummy_function at 0x7ff6908317e0>)\n",
      "Profiler: sort_key='time' func_filter=None top_n=5\n",
      "Profiled Function: dummy_function\n",
      "Function Kwargs: {'dummy_arg': 1}\n",
      "Function Result: 1\n",
      "Function Profiling Result: Fri Apr 25 15:45:46 2025    result.prof\n",
      "\n",
      "         3 function calls in 0.006 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.006    0.006    0.006    0.006 1557726220.py:1(dummy_function)\n",
      "        1    0.000    0.000    0.000    0.000 context_managers.py:120(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n",
      "\n",
      "Function Exceptions: None\n"
     ]
    }
   ],
   "source": [
    "@CallGraphTimeProfilerDecorator(sort_key='time', func_filter=None, top_n=5)\n",
    "def dummy_function(dummy_arg):\n",
    "    res = 0\n",
    "    for _ in range(100000):\n",
    "        res +=  1\n",
    "    return  dummy_arg\n",
    "\n",
    "call_graph_time_profiler_decorator_profiling_result = dummy_function(dummy_arg=1)\n",
    "print(repr(call_graph_time_profiler_decorator_profiling_result))\n",
    "print(call_graph_time_profiler_decorator_profiling_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional feature of Time profiling with time profiling decorators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* serializing profiling result to multiple sources during profiling\n",
    "* p.s that functionality is common for all time profiling decorators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageConfig(serializers_strategies=[<SerializerStrategy.JSON: 'json'>, <SerializerStrategy.TXT: 'txt'>, <SerializerStrategy.YAML: 'yaml'>], file_paths=['time_profiling_results.json', 'time_profiling_results.txt', 'time_profiling_results.yaml'], modes=['w', 'w', 'a'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from python_profiling.python_profiling_configs import StorageConfig\n",
    "from python_profiling.python_profiling_enums import SerializerStrategy\n",
    "\n",
    "storages = StorageConfig(\n",
    "    serializers_strategies=[SerializerStrategy.JSON, SerializerStrategy.TXT, SerializerStrategy.YAML],\n",
    "    file_paths=['time_profiling_results.json', 'time_profiling_results.txt', 'time_profiling_results.yaml'],\n",
    "    modes=['w', 'w', 'a']\n",
    "    )\n",
    "storages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @TimeProfilerDecorator(time_profiler_strategy=TimeProfilerStrategy.THREAD_BASED,\n",
    "#                        storages=storages)\n",
    "# def dummy_function(dummy_arg):\n",
    "#     res = 0\n",
    "#     for _ in range(100000):\n",
    "#         res +=  1\n",
    "#     return  dummy_arg\n",
    "\n",
    "\n",
    "# time_profiler_decorator_profiling_result = dummy_function(dummy_arg=1)\n",
    "# print(repr(time_profiler_decorator_profiling_result))\n",
    "# print(time_profiler_decorator_profiling_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Profiling Guide\n",
    "Important to mantion:\n",
    "1. Additional features of memory profiling result are exacly the same as has been\n",
    "shown before\n",
    "2. General idea and api of memory profiling is the same as has been for time profiling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Import memory profilers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_profiling.memory_profiling.peak_memory_profiler import PeakMemoryProfiler\n",
    "from python_profiling.memory_profiling.object_allocation_profiler import ObjectAllocationProfiler\n",
    "from python_profiling.memory_profiling.line_memory_profiler import LineMemoryProfiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_function(dummy_arg):\n",
    "    data = [num for num in range(10000)]\n",
    "    return  dummy_arg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initialize peak memory profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeakMemoryProfiler(nframes=1, key_type='filename', top_n=5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_memory_profiler = PeakMemoryProfiler(nframes=1, key_type='filename', top_n=5)\n",
    "peak_memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Profiling with peak memory profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeakMemoryProfilerResult(profiler=ModelMetaclass, profiled_func=dummy_function)\n",
      "Top 5 memory differences by 'filename':\n",
      "/Users/nazarlenisin/anaconda3/lib/python3.10/asyncio/selector_events.py:0: size=4163 B (+4163 B), count=2 (+2), average=2082 B\n",
      "/Users/nazarlenisin/anaconda3/lib/python3.10/tracemalloc.py:0: size=1008 B (+1008 B), count=6 (+6), average=168 B\n",
      "/Users/nazarlenisin/Desktop/Profiling Project V2/python_profiling/memory_profiling/peak_memory_profiler.py:0: size=584 B (+584 B), count=2 (+2), average=292 B\n",
      "/Users/nazarlenisin/anaconda3/lib/python3.10/site-packages/IPython/core/history.py:0: size=544 B (+544 B), count=8 (+8), average=68 B\n",
      "/var/folders/k9/6y59tr5d45s1nynfg_sv5zr80000gn/T/ipykernel_24763/376997781.py:0: size=416 B (+416 B), count=1 (+1), average=416 B\n",
      "\n",
      "Top 5 allocations by 'traceback':\n",
      "Memory block: 4.07 KB in 2 allocations\n",
      "  -   File \"/Users/nazarlenisin/anaconda3/lib/python3.10/asyncio/selector_events.py\", line 115\n",
      "  -     data = self._ssock.recv(4096)\n",
      "\n",
      "Memory block: 0.57 KB in 2 allocations\n",
      "  -   File \"/Users/nazarlenisin/Desktop/Profiling Project V2/python_profiling/memory_profiling/peak_memory_profiler.py\", line 47\n",
      "  -     func_result =  func(**kwargs)\n",
      "\n",
      "Memory block: 0.49 KB in 3 allocations\n",
      "  -   File \"/Users/nazarlenisin/anaconda3/lib/python3.10/tracemalloc.py\", line 423\n",
      "  -     self.traces = _Traces(traces)\n",
      "\n",
      "Memory block: 0.45 KB in 2 allocations\n",
      "  -   File \"/Users/nazarlenisin/anaconda3/lib/python3.10/tracemalloc.py\", line 560\n",
      "  -     return Snapshot(traces, traceback_limit)\n",
      "\n",
      "Memory block: 0.41 KB in 1 allocations\n",
      "  -   File \"/var/folders/k9/6y59tr5d45s1nynfg_sv5zr80000gn/T/ipykernel_24763/376997781.py\", line 2\n",
      "  -     data = [num for num in range(10000)]\n",
      "\n",
      "Profiler: <class 'python_profiling.memory_profiling.peak_memory_profiler.PeakMemoryProfiler'>\n",
      "Profiled Function: dummy_function\n",
      "Function Kwargs: {'dummy_arg': 1}\n",
      "Function Result: 1\n",
      "Current memory: 7547.000000 KB\n",
      "Peak memory: 365455.000000 KB\n",
      "Allocation before: <tracemalloc.Snapshot object at 0x7ff69086f850>KB\n",
      "Allocation after: <tracemalloc.Snapshot object at 0x7ff69086eb00>\n",
      "Allocation after statictics: <bound method Snapshot.statistics of <tracemalloc.Snapshot object at 0x7ff69086eb00>>\n",
      "Function Exception: None\n"
     ]
    }
   ],
   "source": [
    "peak_memory_profiler_profiling_result = peak_memory_profiler.profile(func=dummy_function, **{'dummy_arg': 1})\n",
    "print(repr(peak_memory_profiler_profiling_result))\n",
    "print(peak_memory_profiler_profiling_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initialize object allocation memory profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectAllocationProfiler()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_allocation_memory_profiler = ObjectAllocationProfiler()\n",
    "object_allocation_memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Profiling with object allocation memory profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ObjectAllocationProfilerResult(profiler=ObjectAllocationProfiler, profiled_func=dummy_function)\n",
      "Profiler: <class 'python_profiling.memory_profiling.object_allocation_profiler.ObjectAllocationProfiler'>\n",
      "Profiled Function: dummy_function\n",
      "Function Kwargs: {'dummy_arg': 1}\n",
      "Function Result: 1\n",
      "Tracker: <pympler.tracker.SummaryTracker object at 0x7ff69086fa60>\n",
      "Before memory allocation:                             types |   # objects |   total size\n",
      "================================= | =========== | ============\n",
      "                             list |       14600 |      1.23 MB\n",
      "                              str |       14601 |      1.04 MB\n",
      "                              int |        3251 |     88.89 KB\n",
      "                             code |           0 |    289     B\n",
      "            function (store_info) |           1 |    144     B\n",
      "                     _io.StringIO |           1 |    136     B\n",
      "            weakref.ReferenceType |           1 |     72     B\n",
      "         functools._lru_list_elem |           1 |     56     B\n",
      "  concurrent.futures._base.Future |          -1 |    -48     B\n",
      "                            float |          -2 |    -48     B\n",
      "              threading.Condition |          -1 |    -48     B\n",
      "                    _thread.RLock |          -1 |    -64     B\n",
      "             _contextvars.Context |          -1 |    -64     B\n",
      "       function (_call_set_state) |          -1 |   -144     B\n",
      "            function (_set_state) |          -1 |   -144     B\n",
      "After memory allocation:                             types |   # objects |   total size\n",
      "================================= | =========== | ============\n",
      "                             list |       14600 |      1.23 MB\n",
      "                              str |       14601 |      1.04 MB\n",
      "                              int |        3251 |     88.89 KB\n",
      "                             code |           0 |    289     B\n",
      "            function (store_info) |           1 |    144     B\n",
      "                     _io.StringIO |           1 |    136     B\n",
      "            weakref.ReferenceType |           1 |     72     B\n",
      "         functools._lru_list_elem |           1 |     56     B\n",
      "  concurrent.futures._base.Future |          -1 |    -48     B\n",
      "                            float |          -2 |    -48     B\n",
      "              threading.Condition |          -1 |    -48     B\n",
      "                    _thread.RLock |          -1 |    -64     B\n",
      "             _contextvars.Context |          -1 |    -64     B\n",
      "       function (_call_set_state) |          -1 |   -144     B\n",
      "            function (_set_state) |          -1 |   -144     B\n",
      "   types |   # objects |   total size\n",
      "======== | =========== | ============\n",
      "     str |           1 |      1.09 KB\n",
      "    code |           0 |     37     B\n",
      "    list |           0 |     32     B\n",
      "  method |          -1 |    -64     B\n",
      "     int |          -7 |   -196     B\n",
      "   tuple |         -16 |   -768     B\n",
      "Function Exception: None\n"
     ]
    }
   ],
   "source": [
    "object_allocation_memory_profiler_profiling_result = object_allocation_memory_profiler.profile(func=dummy_function, **{'dummy_arg': 1})\n",
    "print(repr(object_allocation_memory_profiler_profiling_result))\n",
    "print(object_allocation_memory_profiler_profiling_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initialize line memory profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LineTimeProfiler()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_memory_profiler = LineMemoryProfiler(interval=0.2, timeout=1, backed='psutil', include_children=True)\n",
    "line_time_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Profiling with line memory profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LineMemoryProfilerResult(profiler=LineMemoryProfiler, profiled_func=dummy_function)\n",
      "Profiler: <class 'python_profiling.memory_profiling.line_memory_profiler.LineMemoryProfiler'>\n",
      "Profiled Function: dummy_function\n",
      "Function Kwargs: {'dummy_arg': 1}\n",
      "Function Result: 1\n",
      "Start Memory: 142.01953125 MiB\n",
      "Peak Memory: 142.0703125 MiB\n",
      "End memory: 142.0703125 MiB\n",
      "Max memory increase: 0.05078125 MiB\n",
      "Memory timeline: [142.01953125, 142.0234375, 142.0703125]\n",
      "Function Exception: None\n"
     ]
    }
   ],
   "source": [
    "line_memory_profiler_profiler_profiling_result = line_memory_profiler.profile(func=dummy_function, **{'dummy_arg': 1})\n",
    "print(repr(line_memory_profiler_profiler_profiling_result))\n",
    "print(line_memory_profiler_profiler_profiling_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time profiling with memory profiling decorators\n",
    "Important to mantion:\n",
    "1. General idea and api of profiling memory profiling decorators is the same as has been for time profiling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_profiling.memory_profiling.memory_profiling_decorators import (\n",
    "    ObjectAllocationProfilerDecorator, \n",
    "    LineMemoryProfilerDecorator,\n",
    "    PeakMemoryProfilerDecorator\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Profiling with object allocation memory profiling decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ObjectAllocationProfilerResult(profiler=ObjectAllocationProfiler, profiled_func=dummy_function)\n",
      "Profiler: <class 'python_profiling.memory_profiling.object_allocation_profiler.ObjectAllocationProfiler'>\n",
      "Profiled Function: dummy_function\n",
      "Function Kwargs: {'dummy_arg': 1}\n",
      "Function Result: 1\n",
      "Tracker: <pympler.tracker.SummaryTracker object at 0x7ff69092a890>\n",
      "Before memory allocation:                             types |   # objects |   total size\n",
      "================================= | =========== | ============\n",
      "                             list |       14676 |      1.24 MB\n",
      "                              str |       14665 |      1.05 MB\n",
      "                              int |        3251 |     88.89 KB\n",
      "            function (store_info) |           1 |    144     B\n",
      "                     _io.StringIO |           1 |    136     B\n",
      "                     _thread.lock |           1 |     56     B\n",
      "                            float |          -1 |    -24     B\n",
      "  concurrent.futures._base.Future |          -1 |    -48     B\n",
      "              threading.Condition |          -1 |    -48     B\n",
      "                           method |          -1 |    -64     B\n",
      "                    _thread.RLock |          -1 |    -64     B\n",
      "             _contextvars.Context |          -1 |    -64     B\n",
      "       asyncio.events.TimerHandle |          -1 |   -112     B\n",
      "           function (update_flag) |          -1 |   -144     B\n",
      "       function (_call_set_state) |          -1 |   -144     B\n",
      "After memory allocation:                             types |   # objects |   total size\n",
      "================================= | =========== | ============\n",
      "                             list |       14676 |      1.24 MB\n",
      "                              str |       14665 |      1.05 MB\n",
      "                              int |        3251 |     88.89 KB\n",
      "            function (store_info) |           1 |    144     B\n",
      "                     _io.StringIO |           1 |    136     B\n",
      "                     _thread.lock |           1 |     56     B\n",
      "                            float |          -1 |    -24     B\n",
      "  concurrent.futures._base.Future |          -1 |    -48     B\n",
      "              threading.Condition |          -1 |    -48     B\n",
      "                           method |          -1 |    -64     B\n",
      "                    _thread.RLock |          -1 |    -64     B\n",
      "             _contextvars.Context |          -1 |    -64     B\n",
      "       asyncio.events.TimerHandle |          -1 |   -112     B\n",
      "           function (update_flag) |          -1 |   -144     B\n",
      "       function (_call_set_state) |          -1 |   -144     B\n",
      "   types |   # objects |   total size\n",
      "======== | =========== | ============\n",
      "     str |           0 |      1.02 KB\n",
      "    list |          -1 |    -48     B\n",
      "  method |          -1 |    -64     B\n",
      "Function Exception: None\n"
     ]
    }
   ],
   "source": [
    "@ObjectAllocationProfilerDecorator()\n",
    "def dummy_function(dummy_arg):\n",
    "    data = [num for num in range(10000)]\n",
    "    return  dummy_arg\n",
    "\n",
    "object_allocation_profiler_decorator_profiling_result = dummy_function(dummy_arg=1)\n",
    "print(repr(object_allocation_profiler_decorator_profiling_result))\n",
    "print(object_allocation_profiler_decorator_profiling_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Profiling with line memory profiling decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LineMemoryProfilerResult(profiler=LineMemoryProfiler, profiled_func=dummy_function)\n",
      "Profiler: <class 'python_profiling.memory_profiling.line_memory_profiler.LineMemoryProfiler'>\n",
      "Profiled Function: dummy_function\n",
      "Function Kwargs: {'dummy_arg': 1}\n",
      "Function Result: 1\n",
      "Start Memory: 138.19140625 MiB\n",
      "Peak Memory: 138.19140625 MiB\n",
      "End memory: 138.19140625 MiB\n",
      "Max memory increase: 0.0 MiB\n",
      "Memory timeline: [138.19140625, 138.19140625, 138.19140625]\n",
      "Function Exception: None\n"
     ]
    }
   ],
   "source": [
    "@LineMemoryProfilerDecorator(interval=0.2, timeout=5, backed='psutil', include_children=True)\n",
    "def dummy_function(dummy_arg):\n",
    "    data = [num for num in range(10000)]\n",
    "    return  dummy_arg\n",
    "\n",
    "line_memory_profiler_decorator_profiling_result = dummy_function(dummy_arg=1)\n",
    "print(repr(line_memory_profiler_decorator_profiling_result))\n",
    "print(line_memory_profiler_decorator_profiling_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Profiling with peak memory profiling decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeakMemoryProfilerResult(profiler=ModelMetaclass, profiled_func=dummy_function)\n",
      "Top 5 memory differences by 'lineno':\n",
      "/Users/nazarlenisin/anaconda3/lib/python3.10/tracemalloc.py:558: size=7448 B (+7392 B), count=134 (+133), average=56 B\n",
      "/Users/nazarlenisin/anaconda3/lib/python3.10/tokenize.py:530: size=0 B (-5600 B), count=0 (-100)\n",
      "/Users/nazarlenisin/anaconda3/lib/python3.10/codeop.py:118: size=3803 B (-968 B), count=52 (-17), average=73 B\n",
      "/Users/nazarlenisin/Desktop/Profiling Project V2/python_profiling/memory_profiling/peak_memory_profiler.py:47: size=632 B (+632 B), count=3 (+3), average=211 B\n",
      "/Users/nazarlenisin/anaconda3/lib/python3.10/site-packages/jupyter_client/session.py:99: size=992 B (-614 B), count=4 (-4), average=248 B\n",
      "\n",
      "Top 5 allocations by 'traceback':\n",
      "Memory block: 2526.06 KB in 58586 allocations\n",
      "  -   File \"/Users/nazarlenisin/anaconda3/lib/python3.10/site-packages/pympler/summary.py\", line 132\n",
      "  -     rows.append([otype, count[otype], total_size[otype]])\n",
      "\n",
      "Memory block: 1812.58 KB in 24976 allocations\n",
      "  -   File \"/Users/nazarlenisin/anaconda3/lib/python3.10/site-packages/pympler/summary.py\", line 88\n",
      "  -     lambda f: \"function (%s)\" % f.__name__,\n",
      "\n",
      "Memory block: 198.69 KB in 2609 allocations\n",
      "  -   File \"/Users/nazarlenisin/anaconda3/lib/python3.10/site-packages/pympler/summary.py\", line 97\n",
      "  -     module = [lambda m: \"module(%s)\" % getattr(\n",
      "\n",
      "Memory block: 174.02 KB in 6364 allocations\n",
      "  -   File \"/Users/nazarlenisin/anaconda3/lib/python3.10/site-packages/pympler/summary.py\", line 126\n",
      "  -     total_size[otype] += getsizeof(o)\n",
      "\n",
      "Memory block: 144.93 KB in 1495 allocations\n",
      "  -   File \"/Users/nazarlenisin/anaconda3/lib/python3.10/linecache.py\", line 137\n",
      "  -     lines = fp.readlines()\n",
      "\n",
      "Profiler: <class 'python_profiling.memory_profiling.peak_memory_profiler.PeakMemoryProfiler'>\n",
      "Profiled Function: dummy_function\n",
      "Function Kwargs: {'dummy_arg': 1}\n",
      "Function Result: 1\n",
      "Current memory: 5500962.000000 KB\n",
      "Peak memory: 48959925.000000 KB\n",
      "Allocation before: <tracemalloc.Snapshot object at 0x7ff69092ba60>KB\n",
      "Allocation after: <tracemalloc.Snapshot object at 0x7ff69092baf0>\n",
      "Allocation after statictics: <bound method Snapshot.statistics of <tracemalloc.Snapshot object at 0x7ff69092baf0>>\n",
      "Function Exception: None\n"
     ]
    }
   ],
   "source": [
    "@PeakMemoryProfilerDecorator(nframes=1, key_type='lineno', top_n=5)\n",
    "def dummy_function(dummy_arg):\n",
    "    data = [num for num in range(10000)]\n",
    "    return  dummy_arg\n",
    "\n",
    "peak_memory_profiler_decorator_profiling_result = dummy_function(dummy_arg=1)\n",
    "print(repr(peak_memory_profiler_decorator_profiling_result))\n",
    "print(peak_memory_profiler_decorator_profiling_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional feature of Memory profiling with time profiling decorators\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* serializing profiling result to multiple sources during profiling\n",
    "* p.s that functionality is common for all memory profiling decorators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storages variable defined higher\n",
    "# @PeakMemoryProfilerDecorator(nframes=1, key_type='lineno', top_n=5, storages=storages)\n",
    "# def dummy_function(dummy_arg):\n",
    "#     data = [num for num in range(10000)]\n",
    "#     return  dummy_arg\n",
    "\n",
    "# peak_memory_profiler_decorator_profiling_result = dummy_function(dummy_arg=1)\n",
    "# print(repr(peak_memory_profiler_decorator_profiling_result))\n",
    "# print(peak_memory_profiler_decorator_profiling_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call Graph Profiling Guide\n",
    "Important to mantion:\n",
    "1. Additional features of call graph profiling result are exacly the same as has been\n",
    "shown before\n",
    "2. General idea and api of call graph profiling is the same as has been for time and memory profiling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_profiling.call_graph_profiling.call_graph_profiler import CallGraphProfiler\n",
    "from python_profiling.python_profiling_enums import CallGraphVisualizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_function(dummy_arg):\n",
    "    for _ in range(5):\n",
    "        helper_func()\n",
    "    return dummy_arg\n",
    "    \n",
    "def helper_func():\n",
    "    return [num for num in range(1000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initialize call graph profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CallGraphProfiler(visualizer=<class 'python_profiling.call_graph_profiling.call_graph_visualization.Gprof2dotVisualizer'>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_graph_profiler = CallGraphProfiler(output_file='call_graph_profling_result.prof', \n",
    "                                       visualizer_strategy=CallGraphVisualizers.GPROF2DOT)\n",
    "\n",
    "call_graph_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Profiling with call graph profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call_graph_profiling_result = call_graph_profiler.profile(func=dummy_function, **{'dummy_arg': 1})\n",
    "# print(repr(call_graph_profiling_result))\n",
    "# print(call_graph_profiling_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call graph profiling with call graph profiling decorators\n",
    "Important to mention:\n",
    "1. ever profiling result is exacly the  same as  been shown  before.\n",
    "2. call graph profiling decorators does not have option of serialization to multiple sources\n",
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @CallGraphProfiler(\n",
    "#     output_file='call_graph_profling_result.prof', \n",
    "#     visualizer_strategy=CallGraphVisualizers.GPROF2DOT\n",
    "#     )\n",
    "# def dummy_function(dummy_arg):\n",
    "#     for _ in range(5):\n",
    "#         helper_func()\n",
    "#     return dummy_arg\n",
    "    \n",
    "# def helper_func():\n",
    "#     return [num for num in range(1000)]\n",
    "\n",
    "# call_graph_profiler_decorator_profiling_result = dummy_function(dummy_arg=1)\n",
    "# print(repr(call_graph_profiler_decorator_profiling_result))\n",
    "# print(call_graph_profiler_decorator_profiling_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composed Profiling Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_profiling.composed_profiling.composed_profiler import ComposedProfiler\n",
    "from python_profiling.python_profiling_configs import ComposedProfilingConfig\n",
    "from python_profiling.python_profiling_enums import (\n",
    "    TimeProfilingStrategy, \n",
    "    MemoryProfilingStrategy, \n",
    "    CallGraphProfilingStrategy\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_function(dummy_arg):\n",
    "    for _ in range(5):\n",
    "        helper_func()\n",
    "    return dummy_arg\n",
    "    \n",
    "def helper_func():\n",
    "    return [num for num in range(1000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initialize composed profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComposedProfilingConfig(time_profiler=TimeProfiler(profiling_timer=<built-in function time>), memory_profiler=interval=0.5 timeout=1 backed='psutil' include_children=True)call_graph_profiler=CallGraphProfiler(visualizer=<class 'python_profiling.call_graph_profiling.call_graph_visualization.Gprof2dotVisualizer'>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composed_profiler_config = ComposedProfilingConfig(\n",
    "    time_profiling_strategy=TimeProfilingStrategy.TIME_PROFILER,\n",
    "    memory_profiling_strategy=MemoryProfilingStrategy.LINE_MEMORY_PROFILER,\n",
    "    call_graph_profiling_strategy=CallGraphProfilingStrategy.CALL_GRAPH_PROFILER,\n",
    "    time_profiling_strategy_params = {'profiling_timer': time.time},\n",
    "    memory_profiling_strategy_params = {'interval': 0.5, 'timeout': 1},\n",
    "    call_graph_profiling_strategy_params = {'output_file': 'from_composed.prof'}\n",
    "    )\n",
    "\n",
    "composed_profiler_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Profiling with composed profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComposedProfiler(composed_profiling_config=ComposedProfilingConfig(time_profiler=TimeProfiler(profiling_timer=<built-in function time>), memory_profiler=interval=0.5 timeout=1 backed='psutil' include_children=True)call_graph_profiler=CallGraphProfiler(visualizer=<class 'python_profiling.call_graph_profiling.call_graph_visualization.Gprof2dotVisualizer'>))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composed_profiler = ComposedProfiler(composed_profiling_config=composed_profiler_config)\n",
    "composed_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-25 15:46:43,842 | python_pytorch_profiling_logger | INFO] -> Visualization done successfuly.\n",
      "[2025-04-25 15:46:43,845 | python_pytorch_profiling_logger | INFO] -> Output file from_composed.prof has been removed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ComposedProfilerResult(time_profiling_result=TimeProfilerResult(profiler=TimeProfiler, profiled_func=dummy_function), memory_profiling_result=LineMemoryProfilerResult(profiler=LineMemoryProfiler, profiled_func=dummy_function))call_graph_profiling_result=CallGraphProfilerResult(profiler=ABCMeta, profiled_func=dummy_function)\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Time Profiling Result:\n",
      "Profiler: TimeProfiler(profiling_timer=<built-in function time>)\n",
      "Profiled Function: dummy_function\n",
      "Function Args: None\n",
      "Function Kwargs: {'dummy_arg': 1}\n",
      "Function Result: 1\n",
      "Function Executions Time: 0.003596 seconds\n",
      "Function Exception: None\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Memory Profiling Result:\n",
      "Profiler: <class 'python_profiling.memory_profiling.line_memory_profiler.LineMemoryProfiler'>\n",
      "Profiled Function: dummy_function\n",
      "Function Kwargs: {'dummy_arg': 1}\n",
      "Function Result: 1\n",
      "Start Memory: 151.6640625 MiB\n",
      "Peak Memory: 191.10546875 MiB\n",
      "End memory: 191.10546875 MiB\n",
      "Max memory increase: 39.44140625 MiB\n",
      "Memory timeline: [151.6640625, 191.1015625, 191.10546875]\n",
      "Function Exception: None\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Call Graph Profiling Result: \n",
      "Profiler: <class 'python_profiling.call_graph_profiling.call_graph_profiler.CallGraphProfiler'>\n",
      "Profiled Function: dummy_function\n",
      "Function Kwargs: {'dummy_arg': 1}\n",
      "Function Result: 1\n",
      "Output file: from_composed.prof\n",
      "Function Exception: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "composed_profiler_profiling_result = composed_profiler.profile(func=dummy_function, **{'dummy_arg': 1})\n",
    "print(repr(composed_profiler_profiling_result))\n",
    "print(composed_profiler_profiling_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiling with composed profiling decorators\n",
    "Important to mantion:\n",
    "1. General idea and api of composed profiling decorators is the same as has been for time and memory profiling.\n",
    "2. Composed profiling decorator as time and memory profiling decorators has functionity of serializing data to multiple sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-25 15:46:45,362 | python_pytorch_profiling_logger | INFO] -> Visualization done successfuly.\n",
      "[2025-04-25 15:46:45,366 | python_pytorch_profiling_logger | INFO] -> Output file from_composed.prof has been removed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ComposedProfilerResult(time_profiling_result=TimeProfilerResult(profiler=TimeProfiler, profiled_func=dummy_function), memory_profiling_result=LineMemoryProfilerResult(profiler=LineMemoryProfiler, profiled_func=dummy_function))call_graph_profiling_result=CallGraphProfilerResult(profiler=ABCMeta, profiled_func=dummy_function)\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Time Profiling Result:\n",
      "Profiler: TimeProfiler(profiling_timer=<built-in function time>)\n",
      "Profiled Function: dummy_function\n",
      "Function Args: None\n",
      "Function Kwargs: {'dummy_arg': 1}\n",
      "Function Result: 1\n",
      "Function Executions Time: 0.002444 seconds\n",
      "Function Exception: None\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Memory Profiling Result:\n",
      "Profiler: <class 'python_profiling.memory_profiling.line_memory_profiler.LineMemoryProfiler'>\n",
      "Profiled Function: dummy_function\n",
      "Function Kwargs: {'dummy_arg': 1}\n",
      "Function Result: 1\n",
      "Start Memory: 151.6328125 MiB\n",
      "Peak Memory: 191.1484375 MiB\n",
      "End memory: 191.1484375 MiB\n",
      "Max memory increase: 39.515625 MiB\n",
      "Memory timeline: [151.6328125, 191.12109375, 191.1484375]\n",
      "Function Exception: None\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Call Graph Profiling Result: \n",
      "Profiler: <class 'python_profiling.call_graph_profiling.call_graph_profiler.CallGraphProfiler'>\n",
      "Profiled Function: dummy_function\n",
      "Function Kwargs: {'dummy_arg': 1}\n",
      "Function Result: 1\n",
      "Output file: from_composed.prof\n",
      "Function Exception: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @ComposedProfiler(composed_profiling_config=composed_profiler_config)\n",
    "# def dummy_function(dummy_arg):\n",
    "#     for _ in range(5):\n",
    "#         helper_func()\n",
    "#     return dummy_arg\n",
    "    \n",
    "# def helper_func():\n",
    "#     return [num for num in range(1000)]\n",
    "\n",
    "# composed_profiler_decorator_profiling_result = dummy_function(dummy_arg=1)\n",
    "# print(repr(composed_profiler_decorator_profiling_result))\n",
    "# print(composed_profiler_decorator_profiling_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Profiling and serialization to multiple sources with composed profiling decorators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ComposedProfiler(\n",
    "#     composed_profiling_config=composed_profiler_config,\n",
    "#     storages=storages\n",
    "#     )\n",
    "# def dummy_function(dummy_arg):\n",
    "#     for _ in range(5):\n",
    "#         helper_func()\n",
    "#     return dummy_arg\n",
    "    \n",
    "# def helper_func():\n",
    "#     return [num for num in range(1000)]\n",
    "\n",
    "# composed_profiler_decorator_profiling_result = dummy_function(dummy_arg=1)\n",
    "# print(repr(composed_profiler_decorator_profiling_result))\n",
    "# print(composed_profiler_decorator_profiling_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Profiling Guide\n",
    "Important to mantion:\n",
    "1. Additional features of pytorch  profiling result are exacly the same as has been\n",
    "shown before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_profiling.pytorch_profiler import PyTorchProfiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorchProfilingResult(output_dir=pytorch_profiling_result)\n",
      "PyTorch Profiling Result.\n",
      "\n",
      "Trace Name: `pytorch_trace`  \n",
      "Total Duration: `0.0521 seconds`  \n",
      "Output Directory: `pytorch_profiling_result`  \n",
      "\n",
      "- How to View:\n",
      "    1. Run this in your terminal: tensorboard --logdir=pytorch_profiling_result\n",
      "    2. Then open [http://localhost:6006](http://localhost:6006)\n",
      "\n",
      "- Notes:\n",
      "    1. CPU-only profiling (macOS doesn't support CUDA)\n",
      "    2. View the *\"Profiler\"* tab in TensorBoard\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-04-25 15:46:53 24763:9141549 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2025-04-25 15:46:54 24763:9141549 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2025-04-25 15:46:54 24763:9141549 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "model = torch.nn.Linear(1000, 1000)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "data = torch.randn(20, 1000)\n",
    "target = torch.randn(20, 1000)\n",
    "\n",
    "    \n",
    "with PyTorchProfiler(trace_name='pytorch_trace', output_dir='pytorch_profiling_result') as pytorch_profiler:\n",
    "    for epoch in range(3):\n",
    "        pytorch_profiler.record_function(\"forward\", lambda: model(data))\n",
    "        output = model(data)\n",
    "            \n",
    "        pytorch_profiler.record_function(\"loss\", lambda: loss_fn(output, target))\n",
    "        loss = loss_fn(output, target)\n",
    "            \n",
    "        pytorch_profiler.record_function(\"backward\", lambda: loss.backward(retain_graph=True))\n",
    "        loss.backward(retain_graph=True)\n",
    "            \n",
    "        pytorch_profiler.record_function(\"optimizer_step\", lambda: optimizer.step())\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "pytroch_profiling_result = pytorch_profiler.profiling_summary\n",
    "print(repr(pytroch_profiling_result))\n",
    "print(pytroch_profiling_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
